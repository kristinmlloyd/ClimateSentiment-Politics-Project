---
title: "Untitled"
format: html
---

```{r}

library(ggplot2)
library(dplyr)

```

```{r}

df <- read.csv("Data/processed-data/Senators_sentiment.csv")

```

```{r}

independent_counts <- df %>%
  filter(!is.na(sentiment)) %>%
  count(sentiment)

# Convert sentiment to a factor for proper color mapping
independent_counts <- independent_counts %>%
  mutate(sentiment = factor(sentiment, levels = c(-1, 1), labels = c("Risk", "Opportunity")))

# Bar Plot with green for opportunity and red for risk
ggplot(independent_counts, aes(x = sentiment, y = n, fill = sentiment)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("Risk" = "red", "Opportunity" = "#078d0f")) +
  labs(
    title = "Distribution of Sentiments",
    x = "Sentiment",
    y = "Count",
    fill = "Sentiment Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}

library(ggplot2)
library(dplyr)

# Create grouped data and calculate proportions
grouped_data <- df %>%
  filter(!is.na(sentiment)) %>%
  group_by(party, sentiment) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  group_by(party) %>%
  mutate(Proportion = Count / sum(Count))  # Calculate proportions

# Convert sentiment to factor with labels
grouped_data <- grouped_data %>%
  mutate(sentiment = factor(sentiment, levels = c(-1, 1), labels = c("Risk", "Opportunity")))

# Mosaic Plot
ggplot(grouped_data, aes(x = party, y = Proportion, fill = sentiment)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_fill_manual(values = c("Risk" = "red", "Opportunity" = "#078d0f")) +
  labs(
    title = "Proportional Distribution of Sentiments by Party",
    x = "Party",
    y = "Proportion",
    fill = "Sentiment Type"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 0),
    legend.position = "right",
    plot.title = element_text(hjust = 0.5)
  )

```

```{r}

# First create the heatmap data
heatmap_data <- df %>%
  mutate(
    ideology_bin = cut(ideology_score, 
                      breaks = seq(-1, 1, by = 0.2),
                      labels = c("-1.0 to -0.8", 
                               "-0.8 to -0.6", 
                               "-0.6 to -0.4", 
                               "-0.4 to -0.2", 
                               "-0.2 to 0.0",
                               "0.0 to 0.2",
                               "0.2 to 0.4",
                               "0.4 to 0.6",
                               "0.6 to 0.8",
                               "0.8 to 1.0")),
    sentiment = ifelse(sentiment == 1, "Opportunity", "Risk")
  ) %>%
  group_by(ideology_bin, sentiment) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(ideology_bin) %>%
  mutate(percentage = (count / sum(count)) * 100) %>%
  ungroup()

# Remove NA rows from the heatmap data
heatmap_data <- heatmap_data %>%
  filter(!is.na(ideology_bin))

# Recreate the heatmap with exact red-green color scheme
ggplot(heatmap_data, aes(x = sentiment, y = ideology_bin, fill = percentage)) +
  geom_tile() +
  geom_text(aes(label = sprintf("%.1f", percentage)), 
            color = "black", size = 4) +
  scale_fill_gradientn(
    colors = c("darkred", "red", "yellow", "lightgreen", "darkgreen"),  # Exact color palette
    values = scales::rescale(c(0, 25, 50, 75, 100))  # Specify where colors should appear
  ) +
  labs(
    title = "Heatmap of Ideology Score Ranges by Sentiment (Risk and Opportunity)",
    x = "Sentiment",
    y = "Ideology Score Range",
    fill = "Percentage"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 0, hjust = 0.5),
    axis.text.y = element_text(hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

```

```{r}

install.packages("tidyverse")
install.packages("tidyr")
install.packages("reshape2")
install.packages("usmap")
install.packages("dplyr")

```

```{r, warning=FALSE, message=FALSE}

library(tidyverse)
library(tidyr)
library(reshape2)
library(usmap)
library(dplyr)

```

```{r}

df <- read.csv("Data/processed-data/Senators_sentiment.csv")

```

```{r}

library(dplyr)

# Get unique senators by state with their party
senator_summary <- df %>%
  mutate(full_name = paste(first, last)) %>%  # Combine first and last names
  distinct(state, full_name, party) %>%       # Keep unique combinations of state, name, and party
  arrange(state, full_name) %>%               # Sort by state and name
  group_by(state) %>%
  summarise(
    Senators = paste(paste(full_name, paste0("(", party, ")"), sep = " "), 
                     collapse = ", "),        # Combine names with parties
    Count = n()                               # Count number of senators per state
  ) %>%
  ungroup()

# Print the results
print(senator_summary, n = Inf)

```

```{r}

library(dplyr)
library(usmap)
library(ggplot2)

df <- df %>%
  mutate(state = tolower(state.name[match(state, state.abb)])) # Converts abbreviations to full state names in lowercase

# Process the data for senator party composition by state
state_senators <- df %>%
  distinct(state, party) %>%                           # Get unique state and party combinations
  group_by(state) %>%
  summarise(
    party_composition = case_when(
      all(party == "R") ~ "Republican",
      all(party == "D") ~ "Democrat",
      any(party == "I") & all(party %in% c("I", "D")) ~ "Split (Independent & Democrat)",  # Corrected logic
      any(party == "I") & all(party %in% c("I", "R")) ~ "Split (Independent & Republican)",
      TRUE ~ "Split (Republican & Democrat)"
    ),
    .groups = "drop"
  )

# Define custom colors for the parties
party_colors <- c(
  "Republican" = "red",
  "Democrat" = "blue",
  "Split (Independent & Democrat)" = "yellow",
  "Split (Independent & Republican)" = "orange",
  "Split (Republican & Democrat)" = "purple"
)

# Plot the map with party composition
plot_usmap(data = state_senators, values = "party_composition", regions = "states") +
  scale_fill_manual(
    values = party_colors,
    name = "Party Composition"
  ) +
  labs(
    title = "Senator Party Composition by State",
    subtitle = "Republican, Democrat, Independent, or Split (Half-and-Half Shading)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    panel.background = element_rect(fill = "white"),
    panel.grid = element_blank()
  )

```

```{r}

library(dplyr)
library(usmap)
library(ggplot2)

# Process data to find the dominant sentiment by state
state_sentiment <- df %>%
  filter(!is.na(sentiment)) %>%                # Exclude missing sentiment values
  group_by(state, sentiment) %>%
  summarise(count = n(), .groups = "drop") %>% # Count occurrences by state and sentiment
  group_by(state) %>%
  mutate(
    total = sum(count),                        # Calculate total counts for each state
    proportion = count / total                # Calculate the proportion for each sentiment
  ) %>%
  filter(proportion == max(proportion)) %>%    # Keep only the dominant sentiment
  mutate(sentiment_label = case_when(          # Add labels for sentiment
    sentiment == -1 ~ "risk",
    sentiment == 1 ~ "opportunity"
  )) %>%
  select(state, sentiment_label)

# Plot the US map with the dominant sentiment
plot_usmap(data = state_sentiment, values = "sentiment_label", regions = "states") +
  scale_fill_manual(
    values = c("opportunity" = "green", 
               "risk" = "red"),                # Define colors for each sentiment
    name = "Sentiment",
    breaks = c("opportunity", "risk"),  
    labels = c("Opportunity", "Risk")         # Customize legend labels
  ) +
  labs(
    title = "Dominant Sentiment by State", 
    subtitle = "Opportunity vs. Risk"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12)
  )

```

```{r}

library(dplyr)
library(usmap)
library(ggplot2)

# Process data to find the sentiment distribution and identify mixed states
state_sentiment <- df %>%
  filter(!is.na(sentiment)) %>%                # Exclude missing sentiment values
  group_by(state, sentiment) %>%
  summarise(count = n(), .groups = "drop") %>% # Count occurrences by state and sentiment
  group_by(state) %>%
  mutate(
    total = sum(count),                        # Calculate total counts for each state
    proportion = count / total                # Calculate the proportion for each sentiment
  ) %>%
  summarise(
    max_proportion = max(proportion),         # Identify the maximum sentiment proportion
    sentiment_label = case_when(
      max_proportion < 0.6 ~ "mixed",         # Mixed if no sentiment exceeds 60%
      sentiment[which.max(proportion)] == -1 ~ "risk", # Risk dominates
      sentiment[which.max(proportion)] == 1 ~ "opportunity" # Opportunity dominates
    ),
    .groups = "drop"
  )

# Plot the US map with mixed sentiment
plot_usmap(data = state_sentiment, values = "sentiment_label", regions = "states") +
  scale_fill_manual(
    values = c(
      "opportunity" = "green", 
      "risk" = "red", 
      "mixed" = "purple"           # Mixed states are shaded purple
    ),
    name = "Sentiment",
    breaks = c("opportunity", "risk", "mixed"),
    labels = c("Opportunity", "Risk", "Mixed") # Customize legend labels
  ) +
  labs(
    title = "Sentiment Distribution by State", 
    subtitle = "Opportunity, Risk, or Mixed Sentiment"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12)
  )

```
```{r}

ggplot(df, aes(x = party, y = ideology_score, fill = party)) +
  geom_violin(alpha = 0.7) +
  geom_boxplot(width = 0.2, alpha = 0.7) +
  scale_fill_manual(values = c("D" = "#00AEF3", 
                              "R" = "#E81B23", 
                              "I" = "#A45FE6")) +
  labs(title = "Distribution of Ideology Scores by Party",
       x = "Party",
       y = "Ideology Score (-1 = Liberal, 1 = Conservative)") +
  theme_minimal()

```

```{r}

library(ggplot2)

# Scatter plot for sentiment vs. ideology by party
ggplot(df, aes(x = ideology_score, y = sentiment, color = party)) +
  geom_jitter(alpha = 0.6, width = 0.1, height = 0.1) +  # Add jitter for better visualization
  scale_color_manual(values = c("D" = "#00AEF3", "R" = "#E81B23", "I" = "#A45FE6")) +
  labs(
    title = "Sentiment vs. Ideology by Party",
    x = "Ideology Score (-1 = Liberal, 1 = Conservative)",
    y = "Sentiment (-1 = Risk, 1 = Opportunity)",
    color = "Party"
  ) +
  theme_minimal()


```

```{r}

df %>%
  mutate(region = case_when(
    state %in% c("maine", "vermont", "new hampshire", "massachusetts", 
                 "rhode island", "connecticut", "new york", "pennsylvania", 
                 "new jersey") ~ "Northeast",
    state %in% c("florida", "georgia", "alabama", "south carolina", 
                 "north carolina", "virginia", "west virginia", "kentucky",
                 "tennessee", "mississippi", "louisiana", "arkansas") ~ "South",
    state %in% c("north dakota", "south dakota", "nebraska", "kansas", 
                 "minnesota", "iowa", "missouri", "wisconsin", "illinois", 
                 "indiana", "michigan", "ohio") ~ "Midwest",
    state %in% c("washington", "oregon", "california", "nevada", "idaho", 
                 "montana", "wyoming", "utah", "colorado", "arizona", 
                 "new mexico", "alaska", "hawaii") ~ "West",
    TRUE ~ "Other"
  )) %>%
  group_by(region, party) %>%
  summarise(count = n(), .groups = "drop") %>%
  ggplot(aes(x = region, y = count, fill = party)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_fill_manual(values = c("R" = "#E81B23", "D" = "#00AEF3", "I" = "#A45FE6")) +
  labs(
    title = "Party Composition by Region",
    subtitle = "Distribution of Political Parties Across US Regions",
    x = "Region",
    y = "Proportion",
    fill = "Party"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5),
    legend.position = "bottom"
  )

```

```{r}

df %>%
  mutate(region = case_when(
    state %in% c("maine", "vermont", "new hampshire", "massachusetts", 
                 "rhode island", "connecticut", "maryland", "delaware", "new york", "pennsylvania", 
                 "new jersey") ~ "Northeast",
    state %in% c("florida", "georgia", "alabama", "south carolina", 
                 "north carolina", "virginia", "west virginia", "kentucky",
                 "tennessee", "mississippi", "louisiana", "arkansas", "oklahoma", "texas") ~ "South",
    state %in% c("north dakota", "south dakota", "nebraska", "kansas", 
                 "minnesota", "iowa", "missouri", "wisconsin", "illinois", 
                 "indiana", "michigan", "ohio") ~ "Midwest",
    state %in% c("washington", "oregon", "california", "nevada", "idaho", 
                 "montana", "wyoming", "utah", "colorado", "arizona", 
                 "new mexico", "alaska", "hawaii") ~ "West",
    TRUE ~ "Other"
  )) %>%
  mutate(sentiment_label = case_when(
    sentiment == -1 ~ "Risk",
    sentiment == 1 ~ "Opportunity",
    TRUE ~ "Other"
  )) %>%
  group_by(region, sentiment_label) %>%
  summarise(count = n(), .groups = "drop") %>%
  ggplot(aes(x = region, y = count, fill = sentiment_label)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_fill_manual(values = c(
    "Risk" = "#E74C3C",
    "Opportunity" = "#2ECC71",
    "Other" = "#95A5A6"
  )) +
  labs(
    title = "Risk-Opportunity Distribution by Region",
    subtitle = "Distribution of Risk (-1) vs Opportunity (1) Sentiment",
    x = "Region",
    y = "Proportion",
    fill = "Assessment"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5),
    legend.position = "bottom"
  )

```

```{r}

install.packages("tm")
install.packages("wordcloud")
library(tm)
library(wordcloud)

# Extract the 'message' column
messages <- df$message

# Create a text corpus
corpus <- Corpus(VectorSource(messages))

# Preprocess the text
corpus <- corpus %>%
  tm_map(content_transformer(tolower)) %>%  # Convert to lowercase
  tm_map(removePunctuation) %>%             # Remove punctuation
  tm_map(removeNumbers) %>%                 # Remove numbers
  tm_map(removeWords, stopwords("en"))      # Remove common stopwords

# Create a term-document matrix
tdm <- TermDocumentMatrix(corpus)

# Convert to a matrix
tdm_matrix <- as.matrix(tdm)

# Calculate word frequencies
word_freq <- sort(rowSums(tdm_matrix), decreasing = TRUE)

# Generate the word cloud
wordcloud(
  words = names(word_freq), 
  freq = word_freq, 
  min.freq = 2,                   # Minimum frequency of words to include
  max.words = 100,                # Maximum number of words to display
  colors = brewer.pal(8, "Dark2") # Use a color palette
)

```

```{r}

# Create correlation analysis between ideology_score and sentiment
ggplot(df, aes(x = ideology_score, y = sentiment)) +
  geom_point(aes(color = party), alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE) +
  scale_color_manual(values = c("D" = "#00AEF3", "R" = "#E81B23", "I" = "#A45FE6")) +
  labs(title = "Correlation between Ideology Score and Sentiment",
       x = "Ideology Score",
       y = "Sentiment",
       color = "Party") +
  theme_minimal()

```

```{r}

if (!require(networkD3)) {
  install.packages("networkD3")
}

# Load required libraries
library(dplyr)
library(networkD3)

```

```{r}
# Create two separate flow analyses
flows_party <- df %>%
  mutate(
    sentiment_label = ifelse(sentiment == 1, "Opportunity", "Risk")
  ) %>%
  group_by(party, sentiment_label) %>%
  summarise(value = n(), .groups = "drop")

flows_state <- df %>%
  group_by(state, sentiment) %>%
  mutate(
    sentiment_label = ifelse(sentiment == 1, "Opportunity", "Risk")
  ) %>%
  group_by(state, sentiment_label) %>%
  summarise(value = n(), .groups = "drop")

# Combine the flows
all_flows <- bind_rows(
  flows_party,
  flows_state %>% mutate(party = state) # Rename state column to match structure
)

# Create nodes dataframe
nodes <- data.frame(
  name = c(
    unique(flows_party$party),     # Party nodes
    unique(flows_state$state),     # State nodes
    unique(c("Opportunity", "Risk")) # Sentiment nodes
  )
)

# Create links dataframe
links <- all_flows %>%
  mutate(
    source = match(party, nodes$name) - 1,
    target = match(sentiment_label, nodes$name) - 1,
    value = value
  )

# Create Sankey diagram
sankeyNetwork(Links = links, 
             Nodes = nodes,
             Source = "source",
             Target = "target",
             Value = "value", 
             NodeID = "name",
             sinksRight = TRUE, 
             nodeWidth = 30,
             fontSize = 12, 
             height = 600,
             width = 1000)


```

```{r}

# Create region and party flows
flows_party <- df %>%
  mutate(
    sentiment_label = ifelse(sentiment == 1, "Opportunity", "Risk")
  ) %>%
  group_by(party, sentiment_label) %>%
  summarise(value = n(), .groups = "drop")

flows_region <- df %>%
  mutate(
    region = case_when(
      state %in% c("maine", "vermont", "new hampshire", "massachusetts", 
                   "rhode island", "connecticut", "new york", "pennsylvania", 
                   "new jersey", "maryland", "delaware") ~ "Northeast",
      state %in% c("florida", "georgia", "alabama", "south carolina", 
                   "north carolina", "virginia", "west virginia", "kentucky",
                   "tennessee", "mississippi", "louisiana", "arkansas", "oklahoma", "texas") ~ "South",
      state %in% c("north dakota", "south dakota", "nebraska", "kansas", 
                   "minnesota", "iowa", "missouri", "wisconsin", "illinois", 
                   "indiana", "michigan", "ohio") ~ "Midwest",
      state %in% c("washington", "oregon", "california", "nevada", "idaho", 
                   "montana", "wyoming", "utah", "colorado", "arizona", 
                   "new mexico", "alaska", "hawaii") ~ "West",
      TRUE ~ "Other"
    ),
    sentiment_label = ifelse(sentiment == 1, "Opportunity", "Risk")
  ) %>%
  group_by(region, sentiment_label) %>%
  summarise(value = n(), .groups = "drop")

# Combine the flows
all_flows <- bind_rows(
  flows_party,
  flows_region %>% mutate(party = region) # Rename region column to match structure
)

# Create nodes dataframe
nodes <- data.frame(
  name = c(
    unique(flows_party$party),     # Party nodes (D, R, I)
    unique(flows_region$region),   # Region nodes
    unique(c("Opportunity", "Risk")) # Sentiment nodes
  )
)

# Create links dataframe
links <- all_flows %>%
  mutate(
    source = match(party, nodes$name) - 1,
    target = match(sentiment_label, nodes$name) - 1,
    value = value
  )

# Create Sankey diagram
sankeyNetwork(Links = links, 
             Nodes = nodes,
             Source = "source",
             Target = "target",
             Value = "value", 
             NodeID = "name",
             sinksRight = TRUE, 
             nodeWidth = 30,
             fontSize = 12, 
             height = 600,
             width = 1000)

```

## Statistical Tests

```{r}


# First create region variable
df <- df %>%
  mutate(region = case_when(
    state %in% c("maine", "vermont", "new hampshire", "massachusetts", 
                 "rhode island", "connecticut", "new york", "pennsylvania", 
                 "new jersey", "maryland", "delaware") ~ "Northeast",
    state %in% c("florida", "georgia", "alabama", "south carolina", 
                 "north carolina", "virginia", "west virginia", "kentucky",
                 "tennessee", "mississippi", "louisiana", "arkansas", "oklahoma", "texas") ~ "South",
    state %in% c("north dakota", "south dakota", "nebraska", "kansas", 
                 "minnesota", "iowa", "missouri", "wisconsin", "illinois", 
                 "indiana", "michigan", "ohio") ~ "Midwest",
    state %in% c("washington", "oregon", "california", "nevada", "idaho", 
                 "montana", "wyoming", "utah", "colorado", "arizona", 
                 "new mexico", "alaska", "hawaii") ~ "West",
    TRUE ~ "Other"
  ))

# 1. Chi-square tests
# Party and Sentiment
party_sentiment_table <- table(df$party, df$sentiment)
party_sentiment_chi <- chisq.test(party_sentiment_table)
print("Chi-square test for Party and Sentiment:")
print(party_sentiment_chi)

# Region and Sentiment
region_sentiment_table <- table(df$region, df$sentiment)
region_sentiment_chi <- chisq.test(region_sentiment_table)
print("\nChi-square test for Region and Sentiment:")
print(region_sentiment_chi)

```

```{r}
# Prepare data for logistic regression
model_data <- df %>%
  # Handle NAs
  filter(!is.na(sentiment), !is.na(ideology_score), !is.na(party)) %>%
  # Create region if not exists
  mutate(
    region = case_when(
      state %in% c("maine", "vermont", "new hampshire", "massachusetts", 
                   "rhode island", "connecticut", "new york", "pennsylvania", 
                   "new jersey", "maryland", "delaware") ~ "Northeast",
      state %in% c("florida", "georgia", "alabama", "south carolina", 
                   "north carolina", "virginia", "west virginia", "kentucky",
                   "tennessee", "mississippi", "louisiana", "arkansas", "oklahoma", "texas") ~ "South",
      state %in% c("north dakota", "south dakota", "nebraska", "kansas", 
                   "minnesota", "iowa", "missouri", "wisconsin", "illinois", 
                   "indiana", "michigan", "ohio") ~ "Midwest",
      state %in% c("washington", "oregon", "california", "nevada", "idaho", 
                   "montana", "wyoming", "utah", "colorado", "arizona", 
                   "new mexico", "alaska", "hawaii") ~ "West",
      TRUE ~ "Other"
    ),
    # Convert sentiment to binary (0/1)
    sentiment = ifelse(sentiment == 1, 1, 0),
    # Convert categorical variables to factors
    party = as.factor(party),
    region = as.factor(region)
  )

# Fit logistic regression
log_model <- glm(sentiment ~ ideology_score + party + region, 
                 data = model_data,
                 family = binomial(link = "logit"))

# Print summary
print("Logistic Regression Summary:")
print(summary(log_model))

# Calculate and print odds ratios
odds_ratios <- exp(coef(log_model))
print("\nOdds Ratios:")
print(odds_ratios)

# Calculate confidence intervals
conf_int <- exp(confint(log_model))
print("\nConfidence Intervals for Odds Ratios:")
print(conf_int)

# Model fit statistics
print("\nAIC:")
print(AIC(log_model))
print("\nNull vs Residual Deviance:")
print(paste("Null deviance:", log_model$null.deviance))
print(paste("Residual deviance:", log_model$deviance))

# Pseudo R-squared (McFadden)
null_model <- glm(sentiment ~ 1, data = model_data, family = binomial)
pseudo_r2 <- 1 - log_model$deviance/null_model$deviance
print("\nMcFadden's Pseudo R-squared:")
print(pseudo_r2)

```

Statistical analysis reveals significant patterns in senatorial sentiment. The logistic regression model demonstrates strong predictive power with a McFadden's Pseudo R-squared of 0.6687, explaining approximately 67% of the variance in sentiment expression. Ideology emerges as the most robust predictor (p < 0.001), with more conservative ideology scores associated with decreased likelihood of positive sentiment. Specifically, for each unit increase in ideology score, the odds of positive sentiment decrease by 99.86%. Regional variations are also significant, particularly in the Northeast, where senators are 12.3 times more likely to express positive sentiment compared to their Midwest counterparts (p < 0.05). While party affiliation appears influential, its high standard errors suggest substantial collinearity with ideology scores, making it difficult to isolate pure partisan effects. The model's strong fit (AIC: 147.22) and significant reduction in deviance from 402.13 to 133.22 indicate that ideology and regional factors are crucial determinants of senatorial sentiment expression.

```{r}

# Correlation test between ideology score and sentiment
ideology_correlation <- cor.test(df$ideology_score, df$sentiment)
print("\nCorrelation between Ideology Score and Sentiment:")
print(ideology_correlation)

```

The Pearson correlation test reveals a strong, statistically significant negative relationship between ideology scores and sentiment (r = -0.813, p < 2.2e-16). This correlation coefficient indicates that as ideology scores increase (become more conservative), sentiment scores consistently decrease, and vice versa. The strength of this relationship is particularly notable, as correlations above 0.7 are generally considered strong in social science research. The narrow confidence interval (-0.848 to -0.771) suggests high precision in this estimate. The extremely low p-value (p < 2.2e-16) provides strong evidence against the null hypothesis of no correlation, indicating that this relationship is highly unlikely to have occurred by chance. 

```{r}

# 1. Ideology Score vs Predicted Probabilities
predicted_probs <- predict(log_model, type = "response")
viz_data <- model_data %>%
  mutate(predicted_prob = predicted_probs)

# Probability Plot
ggplot(viz_data, aes(x = ideology_score, y = predicted_prob, color = party)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = TRUE) +
  scale_color_manual(values = c("D" = "#00AEF3", "R" = "#E81B23", "I" = "#A45FE6")) +
  labs(
    title = "Predicted Probability of Positive Sentiment by Ideology Score",
    x = "Ideology Score (-1 = Liberal, 1 = Conservative)",
    y = "Predicted Probability of Positive Sentiment",
    color = "Party"
  ) +
  theme_minimal()

```

There's a strong negative relationship - as ideology becomes more conservative, the probability of positive sentiment decreases sharply. The relationship appears to be non-linear, following a logistic curve that drops most steeply in the middle range of ideology scores. The curve is steepest between ideology scores of -0.25 to 0.5, suggesting this is where changes in ideology have the strongest effect on sentiment

```{r}

# 2. Regional Effects Plot
regional_effects <- model_data %>%
  group_by(region) %>%
  summarise(
    mean_prob = mean(predicted_probs),
    se = sd(predicted_probs)/sqrt(n()),
    lower = mean_prob - 1.96*se,
    upper = mean_prob + 1.96*se
  )

ggplot(regional_effects, aes(x = region, y = mean_prob)) +
  geom_bar(stat = "identity", fill = "#4CAF50", alpha = 0.7) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +
  labs(
    title = "Average Predicted Probability of Positive Sentiment by Region",
    x = "Region",
    y = "Mean Predicted Probability"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}

# 3. Model Performance Visualization
model_data$predicted_class <- ifelse(predicted_probs > 0.5, 1, 0)
conf_matrix <- table(Actual = model_data$sentiment, Predicted = model_data$predicted_class)

```

```{r}

# Create confusion matrix visualization using a heatmap
conf_matrix_df <- as.data.frame(conf_matrix)
ggplot(conf_matrix_df, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "white", size = 8) +
  scale_fill_gradient(low = "#E74C3C", high = "#2ECC71") +
  labs(
    title = "Confusion Matrix",
    subtitle = "Model Classification Performance"
  ) +
  theme_minimal()

```