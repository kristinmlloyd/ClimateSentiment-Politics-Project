---
title: "Sentiment Model"
author: “Kristin Lloyd”
format: 
  html:
    toc: true
    embed-resources: true
    code-fold: true
---

Let's build a sentiment model. First, we import all required packages. 

```{python}

import numpy as np
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import TreebankWordTokenizer
from nltk.stem import WordNetLemmatizer
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import f1_score, confusion_matrix, classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import LinearSVC
from imblearn.over_sampling import SMOTE
from collections import Counter

```

The training data is made up of fake, risky, and opportunistic climate change tweets created by ChatGPT. The test data includes real tweets from 99 U.S. senators and President Donald Trump.

```{python}

train_df = pd.read_csv("../Data/raw-data/train.csv")
test_df = pd.read_csv("../Data/raw-data/test.csv")

```

```{python}

def preprocess(text):

    tokenizer = TreebankWordTokenizer() 
    lemmatizer = WordNetLemmatizer()
    stopwords_list = stopwords.words('english')
    point_noise = string.punctuation + '0123456789'
    
    cleanText = re.sub(r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+', "", text)
    cleanText = re.sub(r'@[a-zA-Z0-9\_\w]+', '', cleanText)
    cleanText = re.sub(r'#[a-zA-Z0-9]+', '', cleanText)
    cleanText = re.sub(r'RT', '', cleanText)
    cleanText = cleanText.lower()
    cleanText = re.sub(r'([https][http][htt][th][ht])', "", cleanText)
    cleanText = ''.join([word for word in cleanText if word not in point_noise])
    cleanText = "".join(word for word in cleanText if ord(word)<128)
    cleanText = tokenizer.tokenize(cleanText)
    cleanText = [lemmatizer.lemmatize(word) for word in cleanText if word not in stopwords_list]
    cleanText = [word for word in cleanText if len(word) >= 2]
    cleanText = ' '.join(cleanText)
    return cleanText

```


```{python}

# Preprocess both datasets

train_df['message'] = train_df['message'].apply(preprocess)
test_df['message'] = test_df['message'].apply(preprocess)

```

```{python}

# Vectorize the text

vector = TfidfVectorizer(ngram_range=(1,20), min_df=2)
train_features = vector.fit_transform(train_df['message'])
test_features = vector.transform(test_df['message'])

```

```{python}

# Split training data for validation
X_train, X_val, y_train, y_val = train_test_split(
    train_features, 
    train_df['sentiment'],
    test_size=0.2,
    shuffle=True,
    random_state=42
)

```

```{python}

# Apply SMOTE
print("Applying SMOTE...")
sm = SMOTE(random_state=42)
X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)

print('Before SMOTE:', Counter(y_train))
print('After SMOTE:', Counter(y_train_sm))

```

```{python}

# Define and train models
names = ['LogisticRegression', 'ForestClassifier', 'NaiveBayes', 'LinearSVM', 'KNNClassifier']
classifiers = [
    LogisticRegression(C=10),
    RandomForestClassifier(criterion='entropy'),
    MultinomialNB(alpha=1),
    LinearSVC(C=10, class_weight=None),
    KNeighborsClassifier(n_neighbors=10)
]

results = []
models = {}

for name, clf in zip(names, classifiers):
    print(f'Training {name}...')
    
    clf.fit(X_train_sm, y_train_sm)
    
    val_pred = clf.predict(X_val)
    test_pred = clf.predict(test_features)
    
    val_accuracy = accuracy_score(y_val, val_pred)
    val_f1 = f1_score(y_val, val_pred, average='macro')
    
    models[name] = clf
    results.append([name, val_accuracy, val_f1])
    
    test_df[f'{name}_predictions'] = test_pred
    
    print(f'{name} - Validation Accuracy: {val_accuracy:.4f}, F1: {val_f1:.4f}')

```

```{python}

# Create and display results
results_df = pd.DataFrame(results, columns=['Classifier', 'Validation Accuracy', 'Validation F1'])
results_df.set_index('Classifier', inplace=True)

print("\nModel Performance on Validation Set:")
print(results_df.sort_values('Validation F1', ascending=False))

```

```{r}

# Save predictions
output_file = "model_predictions.csv"
test_df.to_csv(output_file, index=False)
print(f"\nPredictions saved to {output_file}")

```

```{r}

# Evaluate on test set
if 'sentiment' in test_df.columns:
    print("\nModel Performance on Dataset:")
    for name in names:
        predictions = test_df[f'{name}_predictions']
        accuracy = accuracy_score(test_df['sentiment'], predictions)
        f1 = f1_score(test_df['sentiment'], predictions, average='macro')
        print(f"\n{name}:")
        print(f"Accuracy: {accuracy:.4f}")
        print(f"F1 Score: {f1:.4f}")

```

```{python}

# Read the predictions file
df = pd.read_csv("Senators_predictions.csv")

# Create new column based on majority vote of the three best models
selected_columns = ['LogisticRegression_predictions', 'NaiveBayes_predictions', 'LinearSVM_predictions']
df['model_label'] = df[selected_columns].mode(axis=1).iloc[:,0]

# Drop the individual model prediction columns
for col in df.columns:
    if '_predictions' in col:
        df = df.drop(col, axis=1)

# Save to new file
df.to_csv("../Data/processed-data/Senators_sentiment.csv", index=False)

# Print value counts of the final labels
print("\nDistribution of final model labels:")
print(df['model_label'].value_counts())

```

```{python}

df = pd.read_csv("../Data/processed-data/Senators_sentiment.csv")

matches = (df['model_label'] == df['sentiment']).sum()
total = len(df)
accuracy = matches / total * 100

print(f"Total rows: {total}")
print(f"Matching rows: {matches}")
print(f"Accuracy: {accuracy:.2f}%")

print("\nConfusion Matrix:")
print(pd.crosstab(df['sentiment'], df['model_label'], margins=True))

```



